{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to parse TWARC JSON files using R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first we need to install all of our packages and then activate them (This could take a bit of time, especially Tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"tidyverse\")\n",
    "install.packages(\"tokenizers\")\n",
    "library(tidyverse)\n",
    "library(tokenizers)\n",
    "library(jsonlite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next bring in your JSON file using jsonlite's \"stream_in()\" function.  Replace FILENAME with your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_json_file <- stream_in(file(\"FILENAME.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the file we will do a process called flattening to clean up the data.  We do this using the \"flatten()\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_file <- flatten(raw_json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is flattened we are going to put it into a special kind of dataframe called a tibble!  This is R's new standard for dataframes!  We do this by using the \"as_tibble()\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tibbled_file <- as_tibble(flattened_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a nice formatted table we will do a quick bit of cleaning before we export it back out of R to use in one of our visualization tools.  First we will seperate out just the text from the tweets and then remove duplicate tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only <- tibbled_file[4]\n",
    "no_dupes_text <- text_only %>% distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done this we will turn the result in text instead of a tibble with only one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dupes_string_text <- toString(no_dupes_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we just export the results into a text file that we can feed to programs like Lexos or Voyant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(no_dupes_string_text, \"twarctext.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
